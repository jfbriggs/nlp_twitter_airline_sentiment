{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis On Airline-Related Twitter Data: Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # hide majority of Python warnings that may come up along the way\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10863, 9371), (3622, 9371), (10863,), (3622,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve pickled files\n",
    "with open(\"count_split.pkl\", \"rb\") as count_split:\n",
    "    X_train_count, X_test_count, y_train, y_test = pickle.load(count_split)\n",
    "    \n",
    "with open(\"tfidf_split.pkl\", \"rb\") as tfidf_split:\n",
    "    X_train_tfidf, X_test_tfidf, y_train, y_test = pickle.load(tfidf_split)\n",
    "    \n",
    "# check shapes of resulting\n",
    "X_train_count.shape, X_test_count.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search With Top-Performing Models\n",
    "\n",
    "We'll now attempt some hyperparameter optimization through grid search with the 5 algorithms we chose to move forward with. We'll create parameter grids for each, use scikit-learn's `GridSearchCV` to determine the highest performing parameter combination for each, and then use each \"best performing\" model to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# function to iterate through collection of models and param grids, find optimal parameter values for each]\n",
    "# outputs a dict of refit optimal param models, which we can use to make predictions with test data\n",
    "def run_grid_search(models, param_grids, X, y, metric, n_jobs = None):\n",
    "    result = {}\n",
    "    \n",
    "    for model_name in models.keys():\n",
    "        clf = GridSearchCV(models[model_name], param_grids[model_name], scoring = metric, n_jobs = n_jobs)\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        result[model_name] = clf.best_estimator_\n",
    "        \n",
    "        print(\"Grid search run for model: {}\".format(model_name))\n",
    "        print(\"Score for best estimator: {.2f}\".format(clf.best_score_))\n",
    "        print(\"Best parameters:\")\n",
    "        print(clf.best_params_)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build collection of parameter grids (for grid search) for each algorithm\n",
    "param_grids = {\n",
    "    \"logistic\": {\n",
    "        \"penalty\": [\"l2\", \"elasticnet\", \"none\"],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"random_state\": [1],\n",
    "        \"tol\": [0.0001, 0.001, 0.01],\n",
    "        \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "    },\n",
    "    \"sgd\": {\n",
    "        \"loss\": [\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"],\n",
    "        \"penalty\": [\"l2\", \"l1\", \"elasticnet\"], \n",
    "        \"alpha\": [0.0001, 0.001, 0.01],\n",
    "        \"tol\": [0.001, 0.01],\n",
    "        \"learning_rate\": [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"],\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    \"forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [None, 20, 50, 100],\n",
    "        \n",
    "    },\n",
    "    \"mult_nb\": {\n",
    "        \"alpha\": [0, 0.1, 0.5, 1.0],\n",
    "        \"fit_prior\": [False, True]\n",
    "    },\n",
    "    \"ridge\": {\n",
    "        \"alpha\": [0.1, 0.5, 1.0],\n",
    "        \"normalize\": [True, False],\n",
    "        \"max_iter\": [None, 50, 100, 200],\n",
    "        \"tol\": [0.0001, 0.001, 0.01],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"solver\": [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# create dict of models to move forward with\n",
    "models = {\n",
    "    \"logistic\": LogisticRegression(),\n",
    "    \"sgd\": SGDClassifier(),\n",
    "    \"forest\": RandomForestClassifier(),\n",
    "    \"mult_nb\": MultinomialNB(),\n",
    "    \"ridge\": RidgeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_grid_search(models, param_grids, X_train_count, y_train, metric = \"accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
